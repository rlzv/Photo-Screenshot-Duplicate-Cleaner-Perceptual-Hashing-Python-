From the project root (photo_duplicate_cleaner/):

Install deps:

pip install -r requirements.txt


python -m streamlit run streamlit_app.py

# ðŸ§¹ Photo & Screenshot Duplicate Cleaner (Perceptual Hashing, Python)

A small Python project that scans a folder of images (photos, screenshots, etc.), detects **duplicate / near-duplicate images** using **perceptual hashing**, and helps you:

- Inspect duplicate groups in a **Streamlit UI**
- **Move** duplicate files into a separate folder (keeping one reference image)
- Or **delete** duplicates in place (again, keeping one image per group)

No camera needed â€“ the tool only works on existing image files.

---

## âœ¨ Features

- ðŸ” **Duplicate detection** via perceptual hashes:
  - Supports `phash`, `ahash`, `dhash`, `whash` via `imagehash` library
  - Configurable hash size and Hamming distance threshold
- ðŸ–¼ï¸ **Visual inspection**:
  - Streamlit UI to view each duplicate group with thumbnails
- ðŸ“ **File management**:
  - Move duplicates to a chosen folder (keeps 1 image per group)
  - Optionally delete duplicates directly from disk
- ðŸ§ª Two ways to use:
  - CLI (command line)
  - Streamlit web UI

---

## ðŸ§  Core Idea (Perceptual Hashing)

Instead of comparing raw files (which would only detect exact binary duplicates), we use **perceptual hashing**, which tries to capture *how an image looks*.

High level:

1. Load image â†’ resize â†’ grayscale.
2. Compute a small hash (e.g. 8Ã—8 = 64 bits).
3. Similar-looking images have similar hashes.
4. Compare hashes using **Hamming distance**:
   - Distance = number of differing bits.
   - Distance â‰¤ threshold â†’ images are considered near-duplicates.

This makes the method robust to:
- Small resizes
- Slight crops
- Minor brightness/contrast changes
- Re-encoding artifacts

---

## ðŸ—ï¸ Project Structure

```text
photo_duplicate_cleaner/
â”œâ”€ duplicate_cleaner/
â”‚  â”œâ”€ __init__.py           # exports CLI main() if needed
â”‚  â”œâ”€ cli.py                # CLI entrypoint (argparse)
â”‚  â”œâ”€ image_loader.py       # file discovery (iterating image files)
â”‚  â”œâ”€ hashing.py            # perceptual hashing (imagehash + Pillow)
â”‚  â”œâ”€ similarity.py         # HashedImage model, grouping via Union-Find
â”‚  â”œâ”€ report.py             # console + JSON reports
â”‚  â”œâ”€ actions.py            # move/delete duplicate files
â”œâ”€ main.py                  # simple entrypoint for CLI
â”œâ”€ streamlit_app.py         # Streamlit UI for visual inspection & actions
â”œâ”€ requirements.txt         # Python dependencies
â””â”€ README.md                # (this documentation)
=======
# Photo-Screenshot-Duplicate-Cleaner-Perceptual-Hashing-Python-
>>>>>>> 196fe2a3ac09bec2cb6752de433fb68d3935754e
